<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?fe151ab3944fff51c4da312eeac4eb09";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>
    
    <script async src="https://cdn.staticfile.org/mermaid/8.6.4/mermaid.min.js"></script>

<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>(续1)评价模型 - ZonLin</title><meta name="Description" content="关于作者"><meta property="og:title" content="(续1)评价模型" />
<meta property="og:description" content="这是一个提示 若(部分)数学公式、表达式或图表显示不完整、不正常，请保持网络流畅并刷新等待，加载时间可能较长~ 任何疑问请致邮：E-mail 1.5 数" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://orangesodahub.github.io/zh-cn/continued_1evalutaion-model/" />
<meta property="og:image" content="https://orangesodahub.github.io/logo.png"/>
<meta property="article:published_time" content="2021-07-07T11:52:32+08:00" />
<meta property="article:modified_time" content="2021-07-07T11:52:32+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://orangesodahub.github.io/logo.png"/>

<meta name="twitter:title" content="(续1)评价模型"/>
<meta name="twitter:description" content="这是一个提示 若(部分)数学公式、表达式或图表显示不完整、不正常，请保持网络流畅并刷新等待，加载时间可能较长~ 任何疑问请致邮：E-mail 1.5 数"/>
<meta name="application-name" content="ZonLin">
<meta name="apple-mobile-web-app-title" content="ZonLin"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="canonical" href="https://orangesodahub.github.io/zh-cn/continued_1evalutaion-model/" /><link rel="prev" href="https://orangesodahub.github.io/zh-cn/sophomore-year/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "(续1)评价模型",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/orangesodahub.github.io\/zh-cn\/continued_1evalutaion-model\/"
        },"image": ["https:\/\/orangesodahub.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "数学建模, 运筹学","wordcount":  9417 ,
        "url": "https:\/\/orangesodahub.github.io\/zh-cn\/continued_1evalutaion-model\/","datePublished": "2021-07-07T11:52:32+08:00","dateModified": "2021-07-07T11:52:32+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "ZonLin","logo": "https:\/\/orangesodahub.github.io\/images\/%E4%B8%8B%E8%BD%BD.jpg"},"author": {
                "@type": "Person",
                "name": "记录"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <script>
            
            Array.from(document.getElementsByClassName('language-mermaid')).forEach(el => {
                el.parentElement.outerHTML = `<div class="mermaid">${el.innerText}</div>`
            })
        </script>
        <style>
         
        .mermaid svg {
            display: block;
            margin: auto;
        }
        </style>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/zh-cn/" title="ZonLin"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span>ZonLin</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/zh-cn/posts/"> 所有文章 </a><a class="menu-item" href="/zh-cn/tags/"> 标签 </a><a class="menu-item" href="/zh-cn/categories/"> 分类 </a><a class="menu-item" href="/zh-cn/categories/documentation/"> 文档 </a><a class="menu-item" href="/zh-cn/about/"> 关于 </a><a class="menu-item" href="https://github.com/OrangeSodahub" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item language" title="选择语言">简体中文<i class="fas fa-chevron-right fa-fw"></i>
                        <select class="language-select" id="language-select-desktop" onchange="location = this.value;"><option value="/continued_1evalutaion-model/">English</option><option value="/zh-cn/continued_1evalutaion-model/" selected>简体中文</option></select>
                    </a><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="在此键入" id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/zh-cn/" title="ZonLin"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span>ZonLin</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="在此键入" id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/zh-cn/posts/" title="">所有文章</a><a class="menu-item" href="/zh-cn/tags/" title="">标签</a><a class="menu-item" href="/zh-cn/categories/" title="">分类</a><a class="menu-item" href="/zh-cn/categories/documentation/" title="">文档</a><a class="menu-item" href="/zh-cn/about/" title="">关于</a><a class="menu-item" href="https://github.com/OrangeSodahub" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a><a href="javascript:void(0);" class="menu-item" title="选择语言">简体中文<i class="fas fa-chevron-right fa-fw"></i>
                    <select class="language-select" onchange="location = this.value;"><option value="/continued_1evalutaion-model/">English</option><option value="/zh-cn/continued_1evalutaion-model/" selected>简体中文</option></select>
                </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">(续1)评价模型</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/zh-cn/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>记录</a></span>&nbsp;<span class="post-category">收录于 <a href="/zh-cn/categories/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"><i class="far fa-folder fa-fw"></i>数理统计</a>&nbsp;<a href="/zh-cn/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"><i class="far fa-folder fa-fw"></i>数学建模</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2021-07-07">2021-07-07</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 9417 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 19 分钟&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"></div>
            </div><div class="content" id="content"><div class="details admonition tip">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-lightbulb fa-fw"></i>这是一个提示<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>若(部分)数学公式、表达式或图表显示不完整、不正常，请保持网络流畅并刷新等待，加载时间可能较长~</p>

<p><a href="mailto:gzzyyxy@gmail.com">任何疑问请致邮：E-mail</a></p>
</div>
        </div>
    </div>

<h3 id="15-数据包络分析法dea">1.5 数据包络分析法（DEA）</h3>

<h4 id="151简述">1.5.1简述</h4>

<p>数据包络分析方法(Data Envelopment Analysis,DEA)是运筹学、管理科学与数理经济学交叉研究的一个新领域。它是根据多项投入指标和多项产出指标，利用线性规划的方法，对具有可比性的同类型单位进行相对有效性评价的一种数量分析方法。</p>

<p>DEA是以<u>相对效率概念</u>为基础，以<u>凸分析</u>和<u>线性规划</u>为工具，将评价决策单元的指标分成“输入类”指标和“输出类”指标（成本型和效益型），通过计算各单元的输入与输出之比，不预先设置权重，评价其决策单元相对有效性的多目标分析评价方法。</p>

<p>DEA的基本思路是在保持决策单元间输入或输出不变的情况下，通过输入和输出数据和数据规划模型确定相对有效的生产前沿面，即Pareto最优解构成的面。并根据各<span  class="math">\(DMU\)</span>与生产前沿面的距离情况，确定各<span  class="math">\(DMU\)</span>是否为DEA有效。</p>

<p>术语：</p>

<ol>
<li><span id="Overall Efficiency">(综合)技术效率（overall efficiency,OE）</span>：指在保持决策单元投入不变的情况下，实际产出同理想产出的比值。反映的是决策单元在一定( 最优规模时) 投入要素的生产效率，是对决策单元的资源配置能力、资源使用效率等多方面能力的综合衡量与评价；</li>
<li>纯技术效率（technical efficiency,TE）：如企业由于管理和技术等因素影响的生产效率；</li>
<li>规模效率（scale efficiency,SE）：如由于企业规模因素影响的生产效率；前三者之间满足关系式：<span  class="math">\(OE=TE\times SE\)</span>；</li>
<li>规模报酬：当生产要素同时增加了一倍，如果产量的增加正好是一倍，称之为规模报酬不变（-），如果产量增加多于一倍，则称之为规模报酬递增（Increasing Returns to Scale, IRS），进而，如果产量增加少于一倍，就称为规模报酬递减（Decreasing Returns to Scale, DRS）；不同生产规模下，规模报酬随之改变。一般生产规模小时，投入产出比会随着规模增加而迅速提升，此时为IRS；当生产达到高峰期时，产出与规模成正比而达到最适规模，此时为规模报酬不变；当生产规模过于庞大时，产出增长速度减缓，此时为DRS。</li>
<li>技术有效：输出相对输入而言已达最大，即该决策单元位于生产函数的曲线上；</li>
<li>规模有效：投入量既不偏大也不偏小，处于规模收益不变的状态；</li>
<li>决策单元（DMU-&gt;Decision Making Unit）就是效率评价的对象，可以理解为一个将一定“投入”转化为一定“产出”的实体；</li>
<li><span id="Strongly effective">DEA强有效</span>：任何一项投入的数量都无法减少，除非减少产出的数量或者增加其他至少一种投入的数量；任何一项产出的数量都无法增加，除非增加投入的数量或减少其他至少一种产出的数量；此时同时达到技术有效和规模有效；</li>
<li><span id="Weakly effective">DEA弱有效</span>：无法等比例减少各项投入的数量，除非减少产出的数量；无法等比例增加各项产出的数量，除非增加投入的数量。这种情况下，虽然不能等比例减少投入或增加产出，但某一项或几项（但不是全部）投入可能减少，所以称为弱有效。此时技术有效和规模有效只满足一个；</li>
<li><span id="Production Front">生产前沿面</span>：对于给定的生产要素和产出价格，选择要素投入的最优组合和产出的最优组合，即投入成本最小、产出收益最大的组合。它所对应的生产函数所描述的生产可能性边界就是生产前沿面<sup class="footnote-ref" id="fnref:1"><a class="footnote" href="#fn:1">1</a></sup>：设<span  class="math">\(\omega\gt0,\mu\gt0,L=\{(X,Y)|\omega^TX-\mu^TY=0\},T\subset\{(X,Y)|\omega^TX-\mu^TY\geqslant0 \}\)</span>满足<span  class="math">\(L\bigcap T\not=∅\)</span>，则称<span  class="math">\(L\)</span>为生产可能集<span  class="math">\(T\)</span>的有效面，称<span  class="math">\(L\bigcap T\)</span>为生产前沿面。</li>
<li>投入冗余率：<span  class="math">\(\eta_{ij}\)</span>为决策单元<span  class="math">\(i\)</span>的第<span  class="math">\(j\)</span>个指标的投入冗余率，则<span  class="math">\(\eta={s_j^-\over x_{ij} }\)</span></li>
<li>产出不足率：<span  class="math">\(\rho_{ij}\)</span>为决策单元<span  class="math">\(i\)</span>的第<span  class="math">\(j\)</span>个指标的投入冗余率，则<span  class="math">\(\rho={s_j^+\over y_{ij} }\)</span></li>
</ol>

<p>说明几点：</p>

<ol>
<li>纯技术效率（TE）测度的是当规模报酬可变时，决策单元与生产前沿面的距离；</li>
<li>规模效率（SE）测度的是当规模报酬可变时，生产前沿面与规模报酬不变时的生产前沿面的距离。</li>
</ol>

<h4 id="152数学模型csup2supr规模报酬不变">1.5.2数学模型（C<sup>2</sup>R：规模报酬不变）</h4>

<blockquote>
<p>CCR模式下得到的是综合技术效益，即OE。</p>
</blockquote>

<p>设有<span  class="math">\(n\)</span>个决策单元<span  class="math">\(DMU_i(1\leqslant i\leqslant n)\)</span>，对每个决策单元<span  class="math">\(DMU_i\)</span>，有<span  class="math">\(s\)</span>个输入指标<span  class="math">\(x_{1i},x_{2i},\cdots,x_{si}\)</span>和<span  class="math">\(t\)</span>个输出指标<span  class="math">\(y_{1i},y_{2i},\cdots,y_{ti}\)</span>，即：</p>

<p><span  class="math">\[
DMU_1=\left[\begin{array}{c|c}x_1&y_1 \end{array}\right]^T=\left[\begin{array}{c c c c|c c c c} x_{11}&x_{12}&\cdots&x_{1s}&y_{11}&y_{12}&\cdots&y_{1t} \end{array}\right]^T\\
DMU_2=\left[\begin{array}{c|c}x_2&y_2 \end{array}\right]^T=\left[\begin{array}{c c c c|c c c c} x_{21}&x_{22}&\cdots&x_{2s}&y_{21}&y_{22}&\cdots&y_{2t} \end{array}\right]^T\\
\vdots\\
DMU_n=\left[\begin{array}{c|c}x_n&y_n \end{array}\right]^T=\left[\begin{array}{c c c c|c c c c} x_{n1}&x_{n2}&\cdots&x_{ns}&y_{n1}&y_{n2}&\cdots&y_{nt} \end{array}\right]^T
\]</span></p>

<p>记</p>

<p><span  class="math">\[
X=(x_1,x_2,\cdots,x_n)^T,Y=(y_1,y_2,\cdots,y_n)^T
\]</span></p>

<p>为n个决策单元的输入指标向量和输出指标向量。对单个决策单元<span  class="math">\(DMU_i\)</span>，设</p>

<p><span  class="math">\[
v=(v_1,v_2,\cdots,v_s)^T,u=(u_1,u_2,\cdots,u_t)^T\quad (v\gt 0,u\gt0)
\]</span></p>

<p>为输入指标和输出指标的权向量，则</p>

<p><span  class="math">\[
I_i=v^Tx_i=\sum_{j=1}^sv_jx_{ij},i=1,2,\cdots,n\\
O_i=u^Ty_i=\sum_{j=1}^tu_jy_{ij},i=1,2,\cdots,n
\]</span></p>

<p>为第i决策单元的综合输入评价指标和综合输出评价指标。记</p>

<p><span  class="math">\[
E_i={O_i\over I_i}={u^Ty_i\over v^Tx_i}={\sum_{j=1}^sv_jx_{ij}\over \sum_{j=1}^tu_jy_{ij}}
\]</span></p>

<p>为<span  class="math">\(DMU_i\)</span>的效率评价指标。显然，输入越小，输出越大，则效率越高。在效率评价指标<span  class="math">\(E_i\leqslant1,v\gt0,u\gt0\)</span>的约束条件下，求出一组最优权向量使得第<span  class="math">\(i_0\)</span>个决策单元<span  class="math">\(DMU_{i_0}\)</span>效率<span  class="math">\(E\)</span>达到最大值<span  class="math">\(E_{i_0}\)</span>，即：</p>

<p><span  class="math">\[
\begin{cases}E_{i_0}=max{u^Ty_{i_0}\over v^Tx_{i_0} }\\
s.t.  {u^Ty_i\over v^Tx_i}\leqslant1(i=1,2.\cdots,n),u\gt0,v\gt0\end{cases}
\]</span></p>

<p>其中，权向量<span  class="math">\(v\)</span>和<span  class="math">\(u\)</span>待定。第一个约束条件中<span  class="math">\(i\in[1,n]\)</span>，即其数量为n个。</p>

<p>将上述分式规划转化为等价的线性规划方程组，采用Charnes-Cooper变换，令：</p>

<p><span  class="math">\[
t={1\over v^Tx_i},\omega=tv,\mu=tu
\]</span></p>

<p>则</p>

<p><span  class="math">\[
\begin{cases}max\;\mu^Ty_{i_0}=E_{i_0}\\s.t.\mu^T y_i-\omega^T x_i\leqslant0 ,\omega ^Tx_{i_0}=1,\omega\geqslant0,\mu\geqslant0\end{cases}\tag{P}
\]</span></p>

<blockquote>
<p>推导：<span  class="math">\(\mu=tu\Rightarrow\mu^T=tu^T\Rightarrow t={\mu^T\over u^T}\\max{u^Ty_i\over v^Tx_i}\Rightarrow maxt\;u^Ty_i\Rightarrow max{ {\mu^T\over u^T}u^Ty_i}\Rightarrow max\;{\mu^Ty_i}\)</span></p>

<p>&emsp;&emsp;&emsp;<span  class="math">\(\omega=tv\Rightarrow \omega^T=tv^T,\mu^T=tu^T\\{u^Ty_i\over v^Tx_i}\leqslant1\Rightarrow u^Ty_i-v^Tx_i\leqslant0\Rightarrow {\mu^T\over t}y_i-{\omega^T\over t}x_i\leqslant0\Rightarrow \mu^T y_i-\omega^T x_i\leqslant0\)</span></p>
</blockquote>

<p>线性规划(P)的解<span  class="math">\(\omega^*,\mu^*\)</span>即为<span  class="math">\(DMU_i\)</span>的最优权向量，其使得<span  class="math">\(DMU_i\)</span>的效率值达到最大。另外，作为线性规划的解，<span  class="math">\(\omega^*,\mu^*\)</span>不唯一。最终有效益分析：</p>

<ol>
<li>若最优指标值<span  class="math">\(E_{i_0}=1\)</span>，则称<span  class="math">\(DMU_i\)</span>为DEA弱有效；</li>
<li>若存在最优解<span  class="math">\(\omega^*,\mu^*\)</span>满足<span  class="math">\(\omega^*\gt0,\mu^*\gt0\)</span>，使得<span  class="math">\(E_i=E_{i_0}=1\)</span>，则称<span  class="math">\(DMU_i\)</span>为DEA有效。此时该生产单元<span  class="math">\(DMU_i\)</span>处在<a href="#Production Front" title="点击跳转">生产前沿面</a>上；</li>
<li>若最优解<span  class="math">\(E_{i_0}\lt1\)</span>，则称该决策单元非DEA有效。</li>
</ol>

<p>将上述线性模型（P）取其对偶模型得到（推导见下）：</p>

<p><span  class="math">\[
\begin{aligned}
\begin{cases}min\;\theta\\s.t.&\sum_{i=1}^n\lambda_ix_{ij}\leqslant\theta x_{i_0j}&j=1,2,\cdots,s\\&\sum_{i=1}^n\lambda_iy_{ij}\geqslant y_{i_0j}&j=1,2,\cdots,t\\&\lambda_i\geqslant0,\quad i=1,2,\cdots,n \end{cases}
\end{aligned}\tag{D}
\]</span></p>

<p>也有的地方将其写为矩阵形式：</p>

<p><span  class="math">\[
\begin{aligned}
\begin{cases}min\;\theta\\s.t.&\sum_{i=1}^n\lambda_ix_{i}\leqslant\theta x_{i_0}\\&\sum_{i=1}^n\lambda_iy_{i}\geqslant y_{i_0}\\&\lambda_i\geqslant0,\quad i=1,2,\cdots,n \end{cases}
\end{aligned}\tag{D}
\]</span></p>

<div class="details admonition tip">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-lightbulb fa-fw"></i>约束条件的矩阵形式<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><span  class="math">\(
\lambda_1\left[\begin{matrix}x_{11}\\x_{12}\\\vdots\\x_{1s} \end{matrix}\right]+\lambda_2\left[\begin{matrix}x_{21}\\x_{22}\\\vdots\\x_{2s} \end{matrix}\right]+\cdots+\lambda_n\left[\begin{matrix}x_{n1}\\x_{n2}\\\vdots\\x_{ns} \end{matrix}\right]=\left[\begin{matrix}\lambda_1x_{11}+\lambda_2x_{21}+\cdots+\lambda_nx_{n1}\\\lambda_1x_{12}+\lambda_2x_{22}+\cdots+\lambda_nx_{n2}\\\vdots\\\lambda_1x_{n1}+\lambda_2x_{n2}+\cdots+\lambda_nx_{ns}\\\end{matrix}\right]\leqslant \theta \left[\begin{matrix}x_{i_01}\\x_{i_02}\\\vdots\\x_{i_0s} \end{matrix}\right]\\
\)</span>
（y同上）</div>
        </div>
    </div>

<p>其中<span  class="math">\(\theta=O\!E_{i_0}\)</span>，即第<span  class="math">\({i_0}\)</span>个决策单元的<a href="#Overall Efficiency" title="什么是综合技术效率指标">综合技术效率指标</a>。<span  class="math">\(\lambda=(\lambda_1,\lambda_2,\cdots,\lambda_n)\)</span>是n个<span  class="math">\(DMU\)</span>的组合系数。对<span  class="math">\(\lambda\)</span>有：</p>

<p><span  class="math">\(\sum_{i=1}^n\lambda_i=1\)</span>时，该决策单元为“规模报酬固定”；</p>

<p><span  class="math">\(\sum_{i=1}^n\lambda_i\lt1\)</span>时，该决策单元为“规模报酬递增”；</p>

<p><span  class="math">\(\sum_{i=1}^n\lambda_i\gt1\)</span>时，该决策单元为“规模报酬递减”；</p>

<p>另外值得说明的是，<a href="#constrait condition" title="见“转化推导”中展开式">第一个和第二个约束条件</a>中的<span  class="math">\(x_i=(x_{i1},x_{i2},\cdots x_{is} )\)</span>和<span  class="math">\(y_i=(y_{i1},y_{i2},\cdots y_{it} )\)</span>，共有n个。</p>

<blockquote>
<p>这个模型可以直观地理解为将决策单元<span  class="math">\(DMU_i\)</span>的投入、产出表示为其他决策单元的线性组合。</p>

<p>如果有某个 (或某些) 决策单元的产出量达到决策单元<span  class="math">\(DMU_{i_0}\)</span>的水平 (达到，不一定要超过，第二个约束的含义)，而投入量尽可能小 (第一个约束的含义)，那么会出现<span  class="math">\(O\!E_{i_0}\lt1\)</span>的情况, 此时说明该决策单元存在资源浪费。</p>

<p>反之，如果该决策单元的效率已经是最高的了，那么任何的决策单元都不能使用比它还要少的投入获得同样 (甚至更多) 的产出，这时候<span  class="math">\(O\!E_{i_0}=1\)</span> <sup class="footnote-ref" id="fnref:2"><a class="footnote" href="#fn:2">2</a></sup>。</p>
</blockquote>

<div class="details admonition tip">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-lightbulb fa-fw"></i>转化推导<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>线性规划模型及其对偶模型的一般式：</p>

<p><span  class="math">\[
\begin{cases}max\;c^Tx'\\
\begin{aligned}
s.t.&Ax'\geqslant b\\&x'\geqslant 0\end{aligned}\end{cases}\qquad \qquad
\begin{cases}min\;b^Ty'\\
\begin{aligned}
s.t.&Ay'\leqslant c\\&y'\geqslant 0\end{aligned}\end{cases}
\]</span></p>

<p>则</p>

<p><span  class="math">\[
max\;\mu^Ty_{i_0}\Rightarrow min\,-\!\mu^Ty_{i_0}
\]</span></p>

<p>认为</p>

<p><span  class="math">\[
\begin{aligned}
c&=[\underbrace{0,\cdots,0}_m,-y_{ {i_0}1},\cdots,y_{ {i_0}t}]^T\\
x'&=[\omega_1,\cdots,\omega_s,\mu_1,\cdots,\mu_t]^T\\
A&=\left[\begin{matrix}x_{11}&\cdots&x_{1s}&-y_{11}&\cdots&-y_{1t}\\\vdots&\ddots&\vdots&\vdots&\ddots&\vdots\\x_{n1}&\cdots&x_{ns}&-y_{n1}&\cdots&-y_{nt}\\-x_{ {i_0}1}&\cdots&-x_{ {i_0}s}&0&\cdots&0\end{matrix}\right]\\b&=[\underbrace{0,\cdots,0}_n,-1]^T\end{aligned}
\]</span></p>

<p>则目标函数</p>

<p><span  class="math">\[
max\;b^Ty'\Rightarrow max[\underbrace{0,\cdots,0}_n,-1][\lambda_1,\cdots,\lambda_n,\theta]^T\Rightarrow max\;-\!\theta\Rightarrow min\; \theta
\]</span></p>

<p><span id="constrait condition">约束条件</span></p>

<p><span  class="math">\[
\begin{aligned}
&A^Ty'\leqslant c\\
&\Rightarrow \left[\begin{matrix}
x_{11}&\cdots&x_{n1}&-x_{ {i_0}1}\\
\vdots&\ddots&\vdots&\vdots\\
x_{1s}&\cdots&x_{ns}&-x_{ {i_0}s}\\
-y_{11}&\cdots&-y_{n1}&0\\
\vdots&\ddots&\vdots&\vdots\\
-y_{1t}&\cdots&-y_{nt}&0
\end{matrix}\right]
[\lambda_1,\cdots,\lambda_n,\theta]^T\leqslant[\underbrace{0,\cdots,0}_m，-y_{ {i_0}1},\cdots,-y_{ {i_0}t}]^T\\\\
&\Rightarrow
\begin{cases}
\begin{aligned}
\lambda_1x_{11}+\lambda_2x_{21}+\cdots+\lambda_nx_{n1}-\theta x_{ {i_0}1}&\leqslant0\\
\vdots\\
\lambda_1x_{1s}+\lambda_2x_{2s}+\cdots+\lambda_nx_{ns}-\theta x_{ {i_0}s}&\leqslant0\\
\lambda_1y_{11}+\lambda_2y_{21}+\cdots+\lambda_ny_{n1}&\geqslant y_{ {i_0}1}\\
\vdots\\
\lambda_1y_{1t}+\lambda_2y_{2t}+\cdots+\lambda_ny_{nt}&\geqslant y_{ {i_0}t}\\
\end{aligned}
\end{cases}
\end{aligned}
\]</span></p>
</div>
        </div>
    </div>

<p>在上述模型（D）中引入松弛变量及非阿基米德无穷小<span  class="math">\(\epsilon\)</span>后，得到：</p>

<p><span  class="math">\[
\begin{cases}
min\;O\!E_{i_0}-\epsilon(\sum_{i=1}^ss_i^-+\sum_{i=1}^ts_i^+)\\
\begin{aligned}
s.t.&\sum_{i=1}^n\lambda_ix_{ij}+s_j^-=O\!E_{i0}x_{i_0j}\quad (j=1,2,\cdots,s)\\
&\sum_{i=1}^n\lambda_iy_{ij}-s_j^+=y_{i_0j}\quad (j=1,2,\cdots,t)\\
&\lambda_i\geqslant0(i=1,2.\cdots,n)\\
&s_i^-,s_j^+\geqslant0\quad (i=1,2,\cdots,s;j=1,2,\cdots,t)
\end{aligned}
\end{cases}\tag{D'}
\]</span></p>

<p>或者用矩阵形式表示：</p>

<p><span  class="math">\[
\begin{cases}
min\;\theta-\epsilon(e_1s^-+e_2s^+)\\
\begin{aligned}
s.t.&\sum_{i=1}^n\lambda_ix_i+s^-=\theta x_{i_0}\\
&\sum_{i=1}^n\lambda_iy_i-s^+=y_{i_0}\\
&\lambda\geqslant0\\&s^-,s^+\geqslant0
\end{aligned}
\end{cases}\tag{D'}
\]</span></p>

<p>其中，<span  class="math">\(s^-=(s_1^-,s_2^-,\cdots,s_s^-)\)</span>是<span  class="math">\(s\)</span>项输入指标的松弛变量；<span  class="math">\(s^+=(s_1^+,s_2^+,\cdots,s_t^+)\)</span>是<span  class="math">\(t\)</span>项输出指标的松弛变量；<span  class="math">\(s^-\)</span>成为差额变数，表示该决策单元为达到DEA有效应减少的投入量，<span  class="math">\(s^+\)</span>称为超额变数，为达到DEA有效应增加的产出量。</p>

<p>效益分析：线性规划<span  class="math">\((D')\)</span>的最优解为<span  class="math">\(\lambda^*,s^{*-},s^{*+},\theta^*\)</span>，则</p>

<ol>
<li>若<span  class="math">\(\theta^*=1\)</span>，此时某一<span  class="math">\(s_i^-\)</span>或<span  class="math">\(s_j^+\)</span>为0，则<span  class="math">\(DMU_i\)</span>为,<a href="#Weakly effective" title="什么是强有效">DEA弱有效</a>；</li>
<li>若<span  class="math">\(\theta^*=1\)</span>且有<span  class="math">\(s^{*-}=0,s^{*+}=0\)</span>，则<span  class="math">\(DMU_i\)</span>为<a href="#Strongly effective" title="什么是强有效">DEA强有效</a>；</li>
<li>若<span  class="math">\(\theta^*\lt1\)</span>，则<span  class="math">\(DMU_i\)</span>为非DEA有效，存在资源浪费现象。技术有效和规模有效均不满足。</li>
</ol>

<h4 id="153数学模型bcsup2sup规模报酬可变">1.5.3数学模型（BC<sup>2</sup>：规模报酬可变）</h4>

<blockquote>
<p>当决策单元的规模变化时，技术效益（OE）的测度会受到规模效率的影响。BCC模式则是为了排除规模效率，得到的是纯技术效率，即TE。</p>
</blockquote>

<p>在CCR模型中加入凸性假设条件<span  class="math">\(\sum_{i=1}^n\lambda_i=1\)</span>即得到基于规模报酬变动的BCC模型：</p>

<p><span  class="math">\[
\begin{cases}
min\;O\!E_{i_0}-\epsilon(\sum_{i=1}^ss_i^-+\sum_{i=1}^ts_i^+)\\
\begin{aligned}
s.t.&\sum_{i=1}^n\lambda_ix_{ij}+s_j^-=O\!E_{i0}x_{i_0j}&j=1,2,\cdots,s\\
&\sum_{i=1}^n\lambda_iy_{ij}-s_j^+=y_{i_0j}&j=1,2,\cdots,t\\
&\sum_{i=1}^n\lambda_i=1,\lambda_i\geqslant0(i=1,2.\cdots,n)\\
&s_i^-,s_j^+\geqslant0&i=1,2,\cdots,s;j=1,2,\cdots,t
\end{aligned}
\end{cases}\tag{M}
\]</span></p>

<p>效益分析：若线性规划（M）的最优解为<span  class="math">\(\lambda^*,s^{*-},s^{*+},\theta^*\)</span>，则</p>

<ol>
<li>若<span  class="math">\(\theta^*=1\)</span>，此时某一<span  class="math">\(s_i^-\)</span>或<span  class="math">\(s_j^+\)</span>为0，则<span  class="math">\(DMU_i\)</span>为,<a href="#Weakly effective" title="什么是强有效">DEA弱有效</a>；</li>
<li>若<span  class="math">\(\theta^*=1\)</span>且有<span  class="math">\(s^{*-}=0,s^{*+}=0\)</span>，则<span  class="math">\(DMU_i\)</span>为<a href="#Strongly effective" title="什么是强有效">DEA强有效</a>；</li>
<li>若<span  class="math">\(\theta^*\lt1\)</span>，则<span  class="math">\(DMU_i\)</span>为非DEA有效，存在资源浪费现象。技术有效和规模有效均不满足。</li>
</ol>

<p>利用BCC模型得到排除由于规模变动影响的技术效率为纯技术效率，而CCR模型得到的是综合技术效率值，利用<span  class="math">\(OE=TE\times SE\)</span>可计算出规模效率值。对规模效率：</p>

<ol>
<li>若规模效率值为1，则表示该决策单元处于最优规模效率状态；</li>
<li>若规模效率值为1，则表示该决策单元未达到规模效率最优，应当着重解决规模效率问题。</li>
</ol>

<h4 id="154实际意义">1.5.4实际意义</h4>

<p><a href="https://blog.csdn.net/qq_42374697/article/details/109173778">数据包络分析法（DEA）_2_始于足下_行千里致广大。-CSDN博客</a></p>

<h4 id="155实例3">1.5.5实例<sup class="footnote-ref" id="fnref:3"><a class="footnote" href="#fn:3">3</a></sup></h4>

<p><a href="https://zhuanlan.zhihu.com/p/60853027">DEA (数据包络分析)介绍及 python3 实现 - 知乎 (zhihu.com)</a></p>

<h4 id="156运用deap分析">1.5.6运用DEAP分析</h4>

<p><a href="https://deap.readthedocs.io/en/master/index.html">DEAP documentation — DEAP 1.3.1 documentation</a></p>

<h3 id="16-主成分分析pca">1.6 主成分分析（PCA）</h3>

<h4 id="161简述">1.6.1简述</h4>

<p>PCA是最简单的以特征量分析多元统计分布的方法。通常情况下，这种运算可以被看作是揭露数据的内部结构，从而更好的解释数据的变量的方法。如果一个多元数据集能够在一个高维数据空间坐标系中被显现出来，那么PCA就能够提供一幅比较低维度的图像，这幅图像即为在讯息最多的点上原对象的一个‘投影’。这样可以利用少量的主成分使得数据的维度降低, 并且在方差的角度来说， 这种降维方法损失的信息最少。其经典方法是对协方差矩阵进行特征分解，得出数据的主成分和它们的权值（特征值）。仅保留权重大的成分，舍弃权重小的成分，投影达到降维的目的。</p>

<p>PCA的数学定义是：一个正交化线性变换，把数据变换到一个新的坐标系统中，使得这一数据的任何投影的第一大方差在第一个坐标（称为第一主成分）上，第二大方差在第二个坐标（第二主成分）上，依次类推。详细地说，PCA的主要思想是将n维特征映射到k维上，这k维是全新的正交特征也被称为主成分，是在原有n维特征的基础上重新构造出来的k维特征。PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。通过这种方式获得的新的坐标轴，我们发现，大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是，我们可以忽略余下的坐标轴，只保留前面k个含有绝大部分方差的坐标轴。事实上，这相当于只保留包含绝大部分方差的维度特征，而忽略包含方差几乎为0的特征维度，实现对数据特征的降维处理。</p>

<p>事实上，通过计算数据矩阵的协方差矩阵，然后得到协方差矩阵的特征值特征向量，选择特征值最大(即方差最大)的k个特征所对应的特征向量组成的矩阵。这样就可以将数据矩阵转换到新的空间当中，实现数据特征的降维。由于得到协方差矩阵的特征值特征向量有两种方法：<u>特征值分解协方差矩阵(EVD)</u>、<u>奇异值分解协方差矩阵(SVD)</u>，所以PCA算法有两种实现方法。</p>

<figure>
    <img src="/images/08.png"/> <figcaption>
            <h4>（图示）</h4>
        </figcaption>
</figure>


<h4 id="162原理">1.6.2原理</h4>

<p>对<span  class="math">\(m\)</span>个<span  class="math">\(n\)</span>维样本组成的样本矩阵<span  class="math">\(P_{n\times m}=(P_1,P_2,\cdots,P_m)\)</span>，为主成分分析对象。对于每一个<span  class="math">\(n\)</span>维样本<span  class="math">\(P_i(i=1,2,\cdots,m)\)</span>可在<span  class="math">\(n\)</span>维坐标空间中用矩阵表示</p>

<p><span  class="math">\[P_i=(P_{i1},P_{i2},\cdots,P_{in})^T\]</span></p>

<p>其中<span  class="math">\(P_{ij}(j=1,2,\cdots,n)\)</span>为在第<span  class="math">\(j\)</span>维上的坐标。为了方便后续计算，首先需对其<u>在同一维度上</u>进行中心化(使各个样本在特定维度上的表示以其原点为中心)，即</p>

<p><span  class="math">\[
(P_{1i},P_{2i},\cdots,P_{mi})\Rightarrow(P_{i1}-\mu_i,P_{i2}-\mu_i,\cdots,P_{im}-\mu_i),\mu_i={1\over m}\sum_{l=1}^mP_{li}\tag{1}
\]</span></p>

<p>对于以后的样本<span  class="math">\(P_i\)</span>，均认为其是中心化处理之后的。当前的<span  class="math">\(n\)</span>维空间的自然基（标准正交基）表示为</p>

<p><span  class="math">\[
e_1=(1,0,\cdots,0)^T,e_2=(0,1,\cdots,0)^T,\cdots,e_n=(0,0,\cdots,1)^T
\]</span></p>

<p>则对样本<span  class="math">\(P_{i}\)</span>表示为自然基的线性组合</p>

<p><span  class="math">\[
P_i=P_{i}e_1+P_{i}e_2+\cdots+P_{i}e_n\tag{2}
\]</span></p>

<p>现需找到另外一组基<span  class="math">\(e_1',e_2',\cdots,e_k'(k\lt n)\)</span>，通过将当前<span  class="math">\(n\)</span>维空间变换到另一个<span  class="math">\(k\)</span>维空间，达到降维的目的，同时使丢失的信息（即坐标）达到最低，最大程度保留有效信息。更准确的解释为，变换后仍然为不同与当前的<span  class="math">\(n\)</span>维空间，但从第<span  class="math">\(k+1\)</span>维开始包含的信息（坐标）极少（小），几乎为0而因此可将其忽略，则可认为从<span  class="math">\(n\)</span>维变换到了<span  class="math">\(k\)</span>维。</p>

<p>对当前<span  class="math">\(n\)</span>维空间，第<span  class="math">\(j\)</span>维坐标上保存的含<span  class="math">\(m\)</span>项的样本<span  class="math">\(P\)</span>的坐标信息为</p>

<p><span  class="math">\[
A_j=(A_{j1},A_{j2},\cdots,A_{jm})=(P_{1j},P_{2j},\cdots,P_{mj})(j=1,2,\cdots,n)\tag{3}
\]</span></p>

<p><span id="P">下图</span>更为清晰地表示这一关系：</p>

<p><span  class="math">\[
\begin{array}{c|cccc}&P_1&P_2&\cdots&P_m\\\hline\\A_1&P_{11}&P_{21}&\cdots&P_{m1}\\A_2&P_{12}&P_{22}&\cdots&P_{m2}\\\vdots&&&\vdots&\\A_n&P_{1n}&P_{2n}&\cdots&P_{mn}\end{array}\tag{4}
\]</span></p>

<p>将其记为矩阵<span  class="math">\(P\)</span>，一般地，将自然基在<span  class="math">\(n\)</span>维空间中的表示为</p>

<p><span  class="math">\[
e_1=(e_{11},e_{12},\cdots,e_{1n})^T,e_2=(e_{21},e_{22},\cdots,e_{2n})^T,\cdots,e_n=(e_{n1},e_{n2},\cdots,e_{nn})^T\tag{5}
\]</span></p>

<p>由点积的表示可知，对第<span  class="math">\(j\)</span>维坐标有</p>

<p><span  class="math">\[
A_{j1}=P_{1j}=e_j^TP_1=\left[\begin{matrix}e_{j1}&e_{j2}&\cdots&e_{jn} \end{matrix}\right]\left[\begin{matrix}P_{11}\\P_{12}\\\vdots\\P_{1n} \end{matrix}\right]=e_{j1}P_{11}+e_{j2}P_{12+\cdots}+e_{jn}P_{1n}\\A_{j2}=P_{2j}=e_j^TP_2=\left[\begin{matrix}e_{j1}&e_{j2}&\cdots&e_{jn} \end{matrix}\right]\left[\begin{matrix}P_{21}\\P_{22}\\\vdots\\P_{2n} \end{matrix}\right]=e_{j1}P_{21}+e_{j2}P_{22+\cdots}+e_{jn}P_{2n}\\\vdots\\A_{jm}=P_{mj}=e_j^TP_m=\left[\begin{matrix}e_{j1}&e_{j2}&\cdots&e_{jn} \end{matrix}\right]\left[\begin{matrix}P_{m1}\\P_{m2}\\\vdots\\P_{mn} \end{matrix}\right]=e_{j1}P_{m1}+e_{j2}P_{m2+\cdots}+e_{jn}P_{mn}\tag{6}
\]</span></p>

<p>要使变换后的<span  class="math">\(n\)</span>维坐标前<span  class="math">\(k\)</span>维尽可能包含最多信息，借助最小二乘法可知，需使第<span  class="math">\(j\)</span>维坐标</p>

<p><span  class="math">\[
A_{j1}^2+A_{j2}^2+\cdots+A_{jm}^2=\sum_{l=1}^mA_{jl}^2\quad j=1,2,\cdots,k
\]</span></p>

<blockquote>
<p>实际上，主成分分析的一个重要假设就是方差的大小是衡量一组数据所包含信息量大小的标准。若一组数据方差越大，则其包含的信息越多。做基变换的目的之一，是要使大部分信息被保留下来，具体实现方法就是使各维度坐标轴上数据的方差达到最大。</p>

<p>此处，<span  class="math">\({1\over m}\sum_{l=1}^mA_{jl}^2\)</span>恰好为<span  class="math">\(A_j\)</span>的方差<span  class="math">\(Var(A_j)\)</span></p>
</blockquote>

<p>的值最大，则</p>

<p><span  class="math">\[
\begin{aligned}
\sum_{l=1}^mA_{jl}^2&=(e_{j1}P_{11}+e_{j2}P_{12+\cdots}+e_{jn}P_{1n})^2+(e_{j1}P_{21}+e_{j2}P_{22+\cdots}+e_{jn}P_{2n})^2+\cdots\\&+(e_{j1}P_{m1}+e_{j2}P_{m2+\cdots}+e_{jn}P_{mn})^2
\end{aligned}
\]</span></p>

<p>对上式中的每一项<span  class="math">\(A_{jl}^2\)</span>将其展开式分为两部分：平方项<span  class="math">\(B_{jl}\)</span>和二次项<span  class="math">\(C_{jl}\)</span>，则</p>

<p><span  class="math">\[
B_{jl}=\sum_{t=1}^n(e_{jt}P_{lt})^2,\quad C_{jl}=2\sum_{t=1}^n\sum_{s=t+1}^n(e_{jt}P_{lt})(e_{js}P_{ls})=2\sum_{t=1}^n\sum_{s=t+1}^n(e_{jt}e_{js})(P_{lt}P_{ls})
\]</span></p>

<p>其中<span  class="math">\(j=1,2,\cdots,n;l=1,2,\cdots,m\)</span>，则</p>

<p><span  class="math">\[
\begin{aligned}
&\sum_{l=1}^mA_{jl}^2=\sum_{l=1}^m\sum_{t=1}^n(e_{jt}P_{lt})^2+2(\sum_{t=1}^n\sum_{s=t+1}^ne_{jt}e_{js})\sum_{l=1}^m(\sum_{t=1}^n\sum_{s=t+1}^nP_{lt}P_{ls})\\&=(P_{11}^2+P_{21}^2+\cdots+P_{m1}^2)e_{j1}^2+(P_{12}^2+P_{22}^2+\cdots+P_{m2}^2)e_{j2}^2+\cdots+(P_{1n}^2+P_{2n}^2+\cdots+P_{mn}^2)e_{jn}^2\\&+2\sum_{t=1}^n\sum_{s=t+1}^n[(P_{1t}P_{1s}+P_{2t}P_{2s}+\cdots+P_{mt}P_{ms})(e_{jt}e_{js})]
\end{aligned}
\]</span></p>

<p>不难看出，上式为二次型，将其写为矩阵形式</p>

<p><span  class="math">\[
\sum_{l=1}^mA_{jl}^2=e_j^T\left[\begin{matrix}\sum_{l=1}^mP_{l1}^2&\sum_{l=1}^mP_{l1}P_{l2}&\cdots&\sum_{l=1}^mP_{l1}P_{ln}\\\sum_{l=1}^mP_{l2}P_{l1}&\sum_{l=1}^2P_{l2}^2&\cdots&\sum_{l=1}^mP_{l2}P_{ln}\\\vdots&\vdots&\ddots&\vdots\\\sum_{l=1}^mP_{ln}P_{l1}&\sum_{l=1}^mP_{ln}P_{l2}&\cdots&\sum_{l=1}^mP_{ln}^2 \end{matrix}\right]e_j=e_j^TP'e_j\tag{7}
\]</span></p>

<p>这里的矩阵<span  class="math">\(P'\)</span>与矩阵<a href="#P" title="矩阵P"><span  class="math">\(P\)</span></a>的协方差矩阵有关。回到中心化之前的样本可知，这里的<span  class="math">\(A_j=(A_{j1},A_{j2},\cdots,A_{jm})\)</span>是经过中心化处理的，则</p>

<p><span  class="math">\[
\begin{aligned}
&Cov(A_{1},A_{2})={1\over m-1}\sum_{i=1}^nA_{1i}A_{2i}={1\over m-1}\sum_{i=1}^nP_{i1}P_{i2}\\
&Var(A_j)={1\over m-1}\sum_{i=1}^nA_{ji}^2={1\over m-1}\sum_{i=1}^nP_{ij}^2
\end{aligned}
\]</span></p>

<p>此处将<span  class="math">\((m-1)\)</span>改为<span  class="math">\(m\)</span>，不会造成太大误差，且便于计算。则</p>

<p><span  class="math">\[
Q_{n\times n}={1\over m}P'=\left[\begin{matrix}Var(A_1)&Cov(A_1,A_2)&\cdots&Cov(A_1,A_n)\\Cov(A_2,A_1)&Var(A_2)&\cdots&Cov(A_2,A_n)\\\vdots&\vdots&\ddots&\vdots\\Cov(A_n,A_1)&Cov(A_n,A_2)&\cdots&Var(A_n) \end{matrix}\right]\tag{8}
\]</span></p>

<p>协方差矩阵又可用矩阵<span  class="math">\(P\)</span>表示为</p>

<p><span  class="math">\[
Q_{n\times n}={1\over m}P_{n\times m}P^T_{m\times n}\tag{9}
\]</span></p>

<p>(7)式用变换之前的协方差矩阵表示了当前方差。相应地，要使方差的值达到最大，同时使协方差的值达到最小，矩阵<span  class="math">\(P'\)</span>的值不可能改变，因为给定的样本值从根本上无法改变（无论其在不同基下的表示是什么），而必须改变基。</p>

<blockquote>
<p>变换的目的之二，是使协方差化到最小。协方差一定程度上体现了不同数据之间包含的信息的重叠关系，而重复的信息应当剔除掉。不难发现，最优化的变换结果即是对角矩阵，此时协方差均为0，只保留对角元素——方差。</p>
</blockquote>

<h4 id="163基于evd的主成分分析">1.6.3基于EVD的主成分分析</h4>

<p><strong>（1）</strong>对协方差矩阵进行特征值分解</p>

<p>接(7)式，要达到使得前<span  class="math">\(k\)</span>维方差最大，同时不同维之间协方差最小的目的，需将矩阵<span  class="math">\(P'\)</span>变换为对角矩阵。即对原样本进行空间变换后的协方差矩阵为对角矩阵，设其为<span  class="math">\(C\)</span>；设原样本矩阵<span  class="math">\(P\)</span>进行变换后的矩阵为<span  class="math">\(M\)</span>，设变换矩阵为<span  class="math">\(W\)</span>，即<span  class="math">\(M=WP\)</span>，则</p>

<p><span  class="math">\[
C={1\over m}MM^T={1\over m}(WP)(WP)^T=W({1\over m}PP^T)W^T=WQW^T
\]</span></p>

<p>由于<span  class="math">\(C\)</span>为对角阵，则上式反过来是对矩阵<span  class="math">\(Q\)</span>的对角化，则<span  class="math">\(WW^T=I\)</span>，则最大值目标可表示为</p>

<p><span  class="math">\[
\begin{aligned}
&\underset{W}{max} tr(WQW^T)\\
&s.t.\;WW^T=I
\end{aligned}
\]</span></p>

<p>通过拉格朗日乘数法解此最值问题</p>

<p><span  class="math">\[
J(W)=tr(WQW^T)-\lambda(WW^T-I)\\\Downarrow\\{\partial(J(W))\over \partial W}=QW^T+\lambda W^T\\\Downarrow \\QW^T=(-\lambda)W^T
\]</span></p>

<p>因此所求变换矩阵<span  class="math">\(W\)</span>为样本矩阵的协方差矩阵<span  class="math">\(Q\)</span>的特征向量组成的矩阵的转置，并且特征向量按照特征值的大小由大到小进行排列。</p>

<p>也可从线性代数角度出发：由(7)式得知协方差矩阵<span  class="math">\(Q\)</span>为实对称矩阵，已知实对称矩阵一定可对角化，即<span  class="math">\(C=M^TQM\)</span>，且对角矩阵<span  class="math">\(C\)</span>为其特征值排列在对角线上构成的对角矩阵，矩阵<span  class="math">\(M\)</span>为其特征向量单位化后按列排列构成的正交矩阵。不难得出，<span  class="math">\(W=M^T\)</span>，即<span  class="math">\(W\)</span>为其特征向量单位化后按行排列构成的矩阵。注意顺序与特征向量保持对应。</p>

<p><strong>（2）</strong>对协方差矩阵或矩阵<span  class="math">\(P'\)</span>进行奇异值分解</p>

<p>接(7)式，可以写出各维度<span  class="math">\(A_j(j=1,2,\cdots,k;k\lt n)\)</span>的方差表示形式</p>

<p><span  class="math">\[
D_1=e_1^TP'e_1,D_2=e_2^TP'e_2,\cdots,D_n=e_n^TP'e_n
\]</span></p>

<p>对每一维度的<span  class="math">\(D_i\)</span>，矩阵<span  class="math">\(P'\)</span>可进行[奇异值分解](&quot;如何进行奇异值分解？&quot;)(对协方差矩阵进行奇异值分解与此相同，二者之间相差系数n)</p>

<p><span  class="math">\[
P'=U\Sigma V^T=U\Sigma U^T\tag{10}
\]</span></p>

<p>第二个等号成立的原因是<span  class="math">\(P'\)</span>为方阵。其中<span  class="math">\(U\)</span>为正交阵，即<span  class="math">\(UU^T=I\)</span>；<span  class="math">\(\Sigma\)</span>为对角阵，即</p>

<p><span  class="math">\[
\Sigma=\left[\begin{matrix}\sigma_1&0&\cdots&0\\0&\sigma_2&\cdots&0\\\vdots&\vdots&\ddots&\vdots\\0&0&\cdots&\sigma_n \end{matrix}\right]
\]</span></p>

<p>其中，奇异值满足<span  class="math">\(\sigma_1\gt \sigma_2\gt \cdots \gt \sigma_n\)</span>，将分解后的矩阵代回<span  class="math">\(D_i\)</span></p>

<p><span  class="math">\[
D_i=e_i^TP'e_i=e_i^TU\Sigma Ue_i=(U^Te_i)^T\Sigma(U^Te_i)=W_i^T\Sigma W_i,i=1,2,\cdots,n\tag{11}
\]</span></p>

<p>即</p>

<p><span  class="math">\[
\Sigma=W_iD_iW_i^T
\]</span></p>

<p>方阵的奇异值分解和特征值分解并无区别，只是从不同的角度出发。由（11）式明显看出<span  class="math">\(W_i=U^Te_i\)</span>，进而<span  class="math">\(W=U^Te\)</span>即矩阵<span  class="math">\(W\)</span>为变换过后的基，矩阵<span  class="math">\(U^T\)</span>为变换矩阵。而<span  class="math">\(U^T\)</span>由矩阵<span  class="math">\(P'\)</span>(或协方差矩阵)的特征向量按照特征值的大小从大到小以行排列构成。</p>

<p>设最终构成的变换矩阵<span  class="math">\(W\)</span>(或<span  class="math">\(U^T\)</span>)为</p>

<p><span  class="math">\[
W=[w_1,w_2,\cdots,w_n]^T
\]</span></p>

<p><span  class="math">\(w_1,w_2,\cdots,w_n\)</span>为特征向量，则由此变换过后的样本矩阵为</p>

<p><span  class="math">\[
W_{n\times n}P_{n\times m}=M_{n\times m}
\]</span></p>

<p>此时矩阵<span  class="math">\(M\)</span>的第<span  class="math">\(k\)</span>至<span  class="math">\(n\)</span>维上的数据已非常之小，几乎为0。因此将其忽略掉，则变换后的矩阵为</p>

<p><span  class="math">\[
M_{k\times m}
\]</span></p>

<p>显然<span  class="math">\(k\lt n\)</span>，即原样本矩阵的维数从<span  class="math">\(n\)</span>降到了<span  class="math">\(k\)</span>。</p>

<p>综上，运用对协方差矩阵进行分解实现PCA的步骤为：</p>

<ol>
<li>对样本矩阵<span  class="math">\(P_{n\times m}\)</span>进行中心化；</li>
<li>求出矩阵<span  class="math">\(P\)</span>的协方差矩阵 <span  class="math">\(Q_{n\times n}={1\over m}PP^T\)</span>；</li>
<li>求出协方差矩阵的特征值和对应的特征向量（特征值分解或奇异值分解）；</li>
<li>将特征向量按照特征值从大到小以行排列构成变换矩阵<span  class="math">\(W_{n\times n}\)</span>；</li>
<li>对原样本矩阵进行变换<span  class="math">\(M_{n\times m}=WP\)</span>，再进行降维<span  class="math">\(M_{k\times m}\)</span>。</li>
</ol>

<h4 id="164-基于svd的主成分分析">1.6.4 基于SVD的主成分分析</h4>

<p>设有样本矩阵<span  class="math">\(P_{n\times m}=(P_1,P_2,\cdots,P_m)\)</span>，首先对行（维度）进行中心化。再对其进行奇异值分解</p>

<p><span  class="math">\[
P=U\Sigma V^T
\]</span></p>

<p>其中<span  class="math">\(U\)</span>为<span  class="math">\(n\times n\)</span>的酉矩阵，<span  class="math">\(V\)</span>为<span  class="math">\(m\times m\)</span>的酉矩阵，即<span  class="math">\(UU^T=VV^T=I\)</span>。<span  class="math">\(\Sigma\)</span>为<span  class="math">\(m\times n\)</span>的非负对角阵，对角线上为奇异值且奇异值按照从大到小的顺序排列。</p>

<p>由上式可得</p>

<p><span  class="math">\[
PP^T=(U\Sigma V^T)(U\Sigma V^T)^T=U\Sigma^2 U^T\\
P^TP=(U\Sigma V^T)^T(U\Sigma V^T)=V\Sigma^2V^T
\]</span></p>

<p>其中<span  class="math">\(PP^T\)</span>和<span  class="math">\(P^TP\)</span>为<span  class="math">\(n\times n\)</span>和<span  class="math">\(m\times m\)</span>的方阵且为实对称矩阵，由特征值分解可知，（1）方阵<span  class="math">\(PP^T\)</span>的归一化特征向量按列排列构成的矩阵为<span  class="math">\(U\)</span>矩阵，其行向量成为左奇异向量；（2）方阵<span  class="math">\(P^TP\)</span>的归一化特征向量按列排列构成的矩阵为<span  class="math">\(V\)</span>矩阵，其行向量成为右奇异向量；（3）二者的特征值的非零平方根为矩阵<span  class="math">\(P\)</span>的奇异值，并与<span  class="math">\(U\)</span>和<span  class="math">\(V\)</span>的行向量对应。</p>

<p>奇异值的衰减速度非常快，以致前少数部分奇异值的和占据总和的大部分，故可用这少部分来估计整体，达到降维的目的。要降低维度，需用到左奇异矩阵<span  class="math">\(U\)</span></p>

<p><span  class="math">\[
M_{n\times m}=U^TP=U^TU\Sigma V^T=\Sigma V^T
\]</span></p>

<p>矩阵<span  class="math">\(M\)</span>为变换过后的样本矩阵，而矩阵<span  class="math">\(U^T\)</span>即为此时的变换矩阵<span  class="math">\(W\)</span>，<span  class="math">\(W\)</span>的行向量为变换后的空间的基。变换后的样本矩阵均满足所需要求。于是，丢弃掉第<span  class="math">\(k\)</span>至<span  class="math">\(n\)</span>维的数据部分，因为此时这部分数据包含的信息已非常之少，基本上没有贡献作用，则矩阵<span  class="math">\(M\)</span>的维数降到了<span  class="math">\(k\)</span>维。</p>

<blockquote>
<p>不难发现，和协方差矩阵分解有相似之处。此处的变换矩阵<span  class="math">\(W=U^T\)</span>的行向量为方阵<span  class="math">\(PP^T\)</span>的特征向量，此方阵即为样本矩阵的协方差矩阵。</p>
</blockquote>

<p>从另一个角度，可以理解为直接从左奇异矩阵中选取了最大的<span  class="math">\(k\)</span>个<u>列</u>向量按<u>行</u>构成了变换矩阵<span  class="math">\(W_{k\times n}(k\lt n)\)</span>，经过<span  class="math">\(W_{k\times n}P_{n\times m}=M_{k\times m}\)</span>计算后，矩阵的维数从<span  class="math">\(n\)</span>降到了<span  class="math">\(k\)</span>。</p>

<div class="details admonition tip">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-lightbulb fa-fw"></i>右奇异矩阵的作用<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>对矩阵<span  class="math">\(P\)</span>进行奇异值分解后，可将其用下式表示</p>

<p><span  class="math">\[
P_{n\times m}\approx U_{n\times k}\Sigma_{k\times k}V_{k\times m}^T
\]</span></p>

<p>两边左乘<span  class="math">\(U^T_{n\times k}\)</span>则得到<span  class="math">\(\Sigma_{k\times k}V_{k\times m}^T\)</span>，即对矩阵<span  class="math">\(P\)</span>的行进行了压缩，和PCA一致；</p>

<p>两边右乘<span  class="math">\(V_{k\times m}\)</span>则得到<span  class="math">\(U_{n\times k}\Sigma_{k\times k}\)</span>，即对矩阵<span  class="math">\(P\)</span>的列进行了压缩，而PCA只能进行一个方向（维度）方向的压缩。</p>

<p><a href="https://www.cnblogs.com/liangflying/archive/2012/09/25/2701148.html">强大的矩阵奇异值分解(SVD)及其应用 - liangflying - 博客园 (cnblogs.com)</a></p>
</div>
        </div>
    </div>

<h4 id="165维数k的确定">1.6.5维数k的确定</h4>

<h3 id="17-理想解方法">1.7 理想解方法</h3>

<h3 id="18-加权积">1.8 加权积</h3>

<h3 id="19-熵权法">1.9 熵权法</h3>

<h3 id="110-信息熵法">1.10 信息熵法</h3>
<div class="footnotes">

<hr>

<ol>
<li id="fn:1">引自<a href="https://zhuanlan.zhihu.com/p/73096903">数据包络分析法（DEA）——CCR - 知乎 (zhihu.com)</a>
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
<li id="fn:2">引自<a href="https://zhuanlan.zhihu.com/p/60853027">DEA (数据包络分析)介绍及 python3 实现 - 知乎 (zhihu.com)</a>
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>
<li id="fn:3">引自其他网站.
 <a class="footnote-return" href="#fnref:3"><sup>[return]</sup></a></li>
</ol>
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2021-07-07</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://orangesodahub.github.io/zh-cn/continued_1evalutaion-model/" data-title="(续1)评价模型" data-via="https://twitter.com/6k6u7dglok4U1SG" data-hashtags="数学建模,运筹学"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://orangesodahub.github.io/zh-cn/continued_1evalutaion-model/" data-hashtag="数学建模"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Hacker News" data-sharer="hackernews" data-url="https://orangesodahub.github.io/zh-cn/continued_1evalutaion-model/" data-title="(续1)评价模型"><i class="fab fa-hacker-news fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Reddit" data-sharer="reddit" data-url="https://orangesodahub.github.io/zh-cn/continued_1evalutaion-model/"><i class="fab fa-reddit fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Line" data-sharer="line" data-url="https://orangesodahub.github.io/zh-cn/continued_1evalutaion-model/" data-title="(续1)评价模型"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://orangesodahub.github.io/zh-cn/continued_1evalutaion-model/" data-title="(续1)评价模型"><i class="fab fa-weibo fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/zh-cn/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/">数学建模</a>,&nbsp;<a href="/zh-cn/tags/%E8%BF%90%E7%AD%B9%E5%AD%A6/">运筹学</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/zh-cn/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/zh-cn/sophomore-year/" class="prev" rel="prev" title="大二学年（2021-2022）"><i class="fas fa-angle-left fa-fw"></i>大二学年（2021-2022）</a></div>
</div>
</article></div>
            </main><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<footer class="footer">
        <div class="footer-container"><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2019 - 2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/zh-cn/" target="_blank">ZonLin</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span><div><span class="icp-splitter"></span><br class="icp-br"/>
                        <span class="icp"><a href="https://beian.miit.gov.cn/#/Integrated/index">黔ICP备2021002279号-1</a>&nbsp;|&nbsp;</span><span>
                            </a><img src="/images/备案图标.png"/><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=52032102000640" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;">贵公网安备 52032102000640号</a>
                        </span>
                </div>
            </div>
            <span id="busuanzi_container_site_pv">
                Total Visits:<span id="busuanzi_value_site_pv"></span>
            </span>

            <span id="busuanzi_container_site_uv">
                Total Visitors:<span id="busuanzi_value_site_uv"></span>
            </span>
            <script type="text/javascript">document.write(unescape("%3Cspan id='cnzz_stat_icon_1279743727'%3E%3C/span%3E%3Cscript src='https://v1.cnzz.com/z_stat.php%3Fid%3D1279743727%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/algoliasearch@4.2.0/dist/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{},"search":{"algoliaAppID":"PASDMWALPK","algoliaIndex":"index.zh-cn","algoliaSearchKey":"b42948e51daaa93df92381c8e2ac0f93","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
